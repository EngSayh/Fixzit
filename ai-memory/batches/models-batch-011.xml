
You are the "Fixzit Memory Builder" for category: "models".

You are given a batch of source files from the Fixzit codebase, wrapped in <file> tags
inside <batch_content>. Each <file> has a "path" attribute with the repository-relative
file path, and its contents are wrapped in CDATA.

YOUR TASK:
1. Read ALL files in <batch_content>.
2. For EACH file, extract architectural metadata using this schema:

[
  {
    "file": "repo-relative/path/to/file.ext",
    "category": "models",
    "summary": "One-sentence technical summary of what this file does.",
    "exports": ["ExportedFunctionOrClassName", "..."],
    "dependencies": ["ImportedModuleOrPath", "..."]
  }
]

RULES:
- Return ONLY a valid JSON array.
- NO markdown, NO backticks, NO comments, NO extra text.
- Include an entry for every file in this batch.
- If a file has no exports, use "exports": [].
- If a file has no imports, use "dependencies": [].

<batch_content>

<file path="server/models/souq/Settlement.ts">
<![CDATA[
/**
 * Settlement Model - Manages seller payment settlements
 * @module server/models/souq/Settlement
 */

import mongoose, { Schema, Model, Types } from "mongoose";
import { getModel, MModel } from "@/types/mongoose-compat";

export interface ISettlement {
  _id: Types.ObjectId;
  settlementId: string;
  sellerId: Types.ObjectId;
  orgId: string; // AUDIT-2025-11-29: Changed from org_id to orgId
  escrowAccountId?: Types.ObjectId;
  period: string; // YYYY-MM format
  startDate: Date;
  endDate: Date;
  totalRevenue: number;
  platformFee: number;
  platformFeeRate: number;
  adjustments: number;
  payoutAmount: number;
  status: "pending" | "approved" | "rejected" | "paid" | "cancelled";
  dueDate: Date;
  paidDate?: Date;
  paymentMethod?: string;
  transactionId?: string;
  notes?: string;
  processedBy?: Types.ObjectId;
  processedAt?: Date;
  orderIds: Types.ObjectId[];
  createdAt: Date;
  updatedAt: Date;
}

const SettlementSchema = new Schema<ISettlement>(
  {
    settlementId: {
      type: String,
      required: true,
      unique: true,
      index: true,
    },
    sellerId: {
      type: Schema.Types.ObjectId,
      ref: "SouqSeller",
      required: true,
      index: true,
    },
    escrowAccountId: {
      type: Schema.Types.ObjectId,
      ref: "EscrowAccount",
    },
    orgId: { // AUDIT-2025-11-29: Changed from org_id
      type: String,
      required: true,
      index: true,
    },
    period: {
      type: String,
      required: true,
    },
    startDate: {
      type: Date,
      required: true,
    },
    endDate: {
      type: Date,
      required: true,
    },
    totalRevenue: {
      type: Number,
      required: true,
      default: 0,
    },
    platformFee: {
      type: Number,
      required: true,
      default: 0,
    },
    platformFeeRate: {
      type: Number,
      required: true,
      default: 10, // 10%
    },
    adjustments: {
      type: Number,
      default: 0,
    },
    payoutAmount: {
      type: Number,
      required: true,
      default: 0,
    },
    status: {
      type: String,
      enum: ["pending", "approved", "rejected", "paid", "cancelled"],
      default: "pending",
      index: true,
    },
    dueDate: {
      type: Date,
      required: true,
    },
    paidDate: {
      type: Date,
    },
    paymentMethod: {
      type: String,
    },
    transactionId: {
      type: String,
    },
    notes: {
      type: String,
    },
    processedBy: {
      type: Schema.Types.ObjectId,
      ref: "User",
    },
    processedAt: {
      type: Date,
    },
    orderIds: [
      {
        type: Schema.Types.ObjectId,
        ref: "SouqOrder",
      },
    ],
  },
  {
    timestamps: true,
    collection: "souq_settlements",
  },
);

// Indexes
SettlementSchema.index({ sellerId: 1, period: 1 }, { unique: true });
SettlementSchema.index({ orgId: 1, status: 1 }); // AUDIT-2025-11-29: Changed from org_id
SettlementSchema.index({ dueDate: 1 });

// Pre-save hook to calculate payout amount
SettlementSchema.pre("save", function (next) {
  if (
    this.isModified("totalRevenue") ||
    this.isModified("platformFee") ||
    this.isModified("adjustments")
  ) {
    this.payoutAmount = this.totalRevenue - this.platformFee + this.adjustments;
  }
  next();
});

export const SouqSettlement = getModel<ISettlement>(
  "SouqSettlement",
  SettlementSchema,
);

]]>
</file>

<file path="server/models/souq/SettlementExtended.ts">
<![CDATA[
/**
 * Souq Settlement MongoDB Model
 *
 * Stores settlement statements for seller payouts.
 */

import mongoose, { Schema, Document } from "mongoose";

export interface ISouqSettlement extends Document {
  settlementId: string;
  sellerId: mongoose.Types.ObjectId;
  escrowAccountId?: mongoose.Types.ObjectId;
  period: {
    start: Date;
    end: Date;
  };
  summary: {
    totalOrders: number;
    grossSales: number;
    platformCommissions: number;
    gatewayFees: number;
    vat: number;
    refunds: number;
    chargebacks: number;
    reserves: number;
    netPayout: number;
  };
  transactions: Array<{
    transactionId: string;
    orderId: string;
    type:
      | "sale"
      | "refund"
      | "commission"
      | "gateway_fee"
      | "vat"
      | "reserve_hold"
      | "reserve_release"
      | "adjustment"
      | "chargeback";
    amount: number;
    timestamp: Date;
    description: string;
  }>;
  status: "draft" | "pending" | "approved" | "paid" | "failed" | "rejected";
  generatedAt: Date;
  paidAt?: Date;
  paidDate?: Date; // Backward compatibility
  notes?: string;
  processedBy?: mongoose.Types.ObjectId;
  processedAt?: Date;
  payoutId?: string;
  createdAt: Date;
  updatedAt: Date;
}

const SouqSettlementSchema = new Schema<ISouqSettlement>(
  {
    settlementId: {
      type: String,
      required: true,
      unique: true,
      index: true,
    },
    sellerId: {
      type: Schema.Types.ObjectId,
      required: true,
      ref: "User",
      index: true,
    },
    escrowAccountId: {
      type: Schema.Types.ObjectId,
      ref: "EscrowAccount",
    },
    period: {
      start: { type: Date, required: true },
      end: { type: Date, required: true },
    },
    summary: {
      totalOrders: { type: Number, default: 0 },
      grossSales: { type: Number, default: 0 },
      platformCommissions: { type: Number, default: 0 },
      gatewayFees: { type: Number, default: 0 },
      vat: { type: Number, default: 0 },
      refunds: { type: Number, default: 0 },
      chargebacks: { type: Number, default: 0 },
      reserves: { type: Number, default: 0 },
      netPayout: { type: Number, default: 0 },
    },
    transactions: [
      {
        transactionId: { type: String, required: true },
        orderId: { type: String, required: true },
        type: {
          type: String,
          required: true,
          enum: [
            "sale",
            "refund",
            "commission",
            "gateway_fee",
            "vat",
            "reserve_hold",
            "reserve_release",
            "adjustment",
            "chargeback",
          ],
        },
        amount: { type: Number, required: true },
        timestamp: { type: Date, required: true },
        description: { type: String, required: true },
      },
    ],
    status: {
      type: String,
      required: true,
      enum: ["draft", "pending", "approved", "paid", "failed", "rejected"],
      default: "draft",
      index: true,
    },
    generatedAt: {
      type: Date,
      required: true,
      default: Date.now,
    },
    paidAt: Date,
    paidDate: Date, // Backward compatibility
    notes: String,
    processedBy: {
      type: Schema.Types.ObjectId,
      ref: "User",
    },
    processedAt: Date,
    payoutId: String,
  },
  {
    timestamps: true,
    collection: "souq_settlements",
  },
);

// Indexes
SouqSettlementSchema.index({ sellerId: 1, "period.start": -1 });
SouqSettlementSchema.index({ status: 1, generatedAt: -1 });

export const SouqSettlement =
  (mongoose.models.SouqSettlement as mongoose.Model<ISouqSettlement>) ||
  mongoose.model<ISouqSettlement>("SouqSettlement", SouqSettlementSchema);

]]>
</file>

<file path="server/models/souq/Transaction.ts">
<![CDATA[
/**
 * Souq Transaction MongoDB Model
 *
 * Stores seller transaction history for balance tracking.
 */

import mongoose, { Schema, Document } from "mongoose";

export interface ISouqTransaction extends Document {
  transactionId: string;
  sellerId: mongoose.Types.ObjectId;
  orgId: mongoose.Types.ObjectId; // üîê STRICT v4.1: Required for tenant isolation
  orderId?: string;
  type:
    | "sale"
    | "refund"
    | "commission"
    | "gateway_fee"
    | "vat"
    | "reserve_hold"
    | "reserve_release"
    | "withdrawal"
    | "adjustment"
    | "chargeback";
  amount: number;
  balanceBefore: number;
  balanceAfter: number;
  description: string;
  metadata?: Record<string, unknown>;
  createdBy?: mongoose.Types.ObjectId;
  createdAt: Date;
  updatedAt: Date;
}

const SouqTransactionSchema = new Schema<ISouqTransaction>(
  {
    transactionId: {
      type: String,
      required: true,
      unique: true,
      index: true,
    },
    sellerId: {
      type: Schema.Types.ObjectId,
      required: true,
      ref: "User",
      index: true,
    },
    orgId: {
      type: Schema.Types.ObjectId,
      required: true,
      ref: "Organization",
      index: true,
    },
    orderId: {
      type: String,
      index: true,
    },
    type: {
      type: String,
      required: true,
      enum: [
        "sale",
        "refund",
        "commission",
        "gateway_fee",
        "vat",
        "reserve_hold",
        "reserve_release",
        "withdrawal",
        "adjustment",
        "chargeback",
      ],
      index: true,
    },
    amount: {
      type: Number,
      required: true,
    },
    balanceBefore: {
      type: Number,
      required: true,
    },
    balanceAfter: {
      type: Number,
      required: true,
    },
    description: {
      type: String,
      required: true,
    },
    metadata: {
      type: Schema.Types.Mixed,
    },
    createdBy: {
      type: Schema.Types.ObjectId,
      ref: "User",
    },
  },
  {
    timestamps: true,
    collection: "souq_transactions",
  },
);

// Indexes - üîê STRICT v4.1: Include orgId for tenant isolation
SouqTransactionSchema.index({ orgId: 1, sellerId: 1, createdAt: -1 });
SouqTransactionSchema.index({ orgId: 1, sellerId: 1, type: 1, createdAt: -1 });

export const SouqTransaction =
  (mongoose.models.SouqTransaction as mongoose.Model<ISouqTransaction>) ||
  mongoose.model<ISouqTransaction>("SouqTransaction", SouqTransactionSchema);

]]>
</file>

<file path="server/models/souq/Variation.ts">
<![CDATA[
/**
 * Souq Variation Model - Product variations (SKUs)
 * @module server/models/souq/Variation
 */

import mongoose, { Schema, type Document } from "mongoose";
import { getModel, MModel } from "@/types/mongoose-compat";

export interface IVariation extends Document {
  _id: mongoose.Types.ObjectId;
  variationId: string; // VAR-{UUID}
  fsin: string; // Parent product FSIN
  sku: string; // Unique SKU

  // Variation Attributes
  attributes: Record<string, string | number | boolean>; // { color: 'Red', size: 'L' }

  // Images (variation-specific)
  images?: string[]; // If empty, use parent product images

  // Identifiers
  upc?: string;
  ean?: string;
  gtin?: string;
  manufacturerPartNumber?: string;

  // Physical Properties
  dimensions?: {
    length: number; // cm
    width: number; // cm
    height: number; // cm
    weight: number; // kg
  };

  // Status
  isActive: boolean;

  // Timestamps
  createdAt: Date;
  updatedAt: Date;
}

const VariationSchema = new Schema<IVariation>(
  {
    variationId: {
      type: String,
      required: true,
      unique: true,
      index: true,
    },
    fsin: {
      type: String,
      required: true,
      index: true,
      uppercase: true,
    },
    sku: {
      type: String,
      required: true,
      unique: true,
      index: true,
      uppercase: true,
    },
    attributes: {
      type: Map,
      of: Schema.Types.Mixed,
      required: true,
    },
    images: [String],
    upc: {
      type: String,
      sparse: true,
      index: true,
    },
    ean: {
      type: String,
      sparse: true,
      index: true,
    },
    gtin: {
      type: String,
      sparse: true,
      index: true,
    },
    manufacturerPartNumber: String,
    dimensions: {
      length: Number,
      width: Number,
      height: Number,
      weight: Number,
    },
    isActive: {
      type: Boolean,
      default: true,
      index: true,
    },
  },
  {
    timestamps: true,
    collection: "souq_variations",
  },
);

// Indexes
VariationSchema.index({ fsin: 1, isActive: 1 });
VariationSchema.index({ sku: 1, isActive: 1 });

// Method: Get display name based on attributes
VariationSchema.methods.getDisplayName = function (): string {
  const entries = Array.from(this.attributes.entries()) as [
    string,
    string | number | boolean,
  ][];
  const attrs = entries.map(([key, value]) => `${key}: ${value}`).join(", ");
  return attrs || this.sku;
};

// Method: Calculate volumetric weight
VariationSchema.methods.getVolumetricWeight = function (): number | null {
  if (!this.dimensions) return null;
  const { length, width, height } = this.dimensions;
  // Volumetric weight = (L √ó W √ó H) / 5000 (standard formula)
  return (length * width * height) / 5000;
};

// Static: Find variations by FSIN
VariationSchema.statics.findByFSIN = async function (fsin: string) {
  return this.find({ fsin, isActive: true }).sort({ createdAt: 1 });
};

// Static: Find variation by SKU
VariationSchema.statics.findBySKU = async function (sku: string) {
  return this.findOne({ sku: sku.toUpperCase(), isActive: true });
};

export const SouqVariation = getModel<IVariation>(
  "SouqVariation",
  VariationSchema,
);

export default SouqVariation;

]]>
</file>

<file path="server/models/workorder/WorkOrderAttachment.ts">
<![CDATA[
import { Schema, Model, InferSchemaType } from "mongoose";
import { getModel } from "@/types/mongoose-compat";
import tenantAuditPlugin from "@/server/models/plugins/tenantAudit";

const UploadedBySchema = new Schema(
  {
    id: String,
    name: String,
    email: String,
  },
  { _id: false },
);

const WorkOrderAttachmentSchema = new Schema(
  {
    // orgId injected by tenantIsolationPlugin
    workOrderId: { type: Schema.Types.ObjectId, ref: "WorkOrder", required: true },
    url: { type: String, required: true },
    thumbnailUrl: String,
    caption: String,
    type: String,
    fileName: String,
    fileSize: Number,
    metadata: Schema.Types.Mixed,
    uploadedAt: { type: Date, default: Date.now },
    uploadedBy: { type: UploadedBySchema, default: {} },
  },
  { timestamps: false, collection: "workorder_attachments" },
);

WorkOrderAttachmentSchema.plugin(tenantAuditPlugin);

WorkOrderAttachmentSchema.index({ orgId: 1, workOrderId: 1, uploadedAt: -1 });
WorkOrderAttachmentSchema.index({ orgId: 1, uploadedAt: -1 });

export type WorkOrderAttachmentDoc = InferSchemaType<typeof WorkOrderAttachmentSchema>;

export const WorkOrderAttachment: Model<WorkOrderAttachmentDoc> =
  getModel<WorkOrderAttachmentDoc>("WorkOrderAttachment", WorkOrderAttachmentSchema);

]]>
</file>

<file path="server/models/workorder/WorkOrderComment.ts">
<![CDATA[
import { Schema, Model, InferSchemaType } from "mongoose";
import { getModel } from "@/types/mongoose-compat";
import tenantAuditPlugin from "@/server/models/plugins/tenantAudit";

const AttachmentSchema = new Schema(
  {
    url: String,
    thumbnailUrl: String,
    caption: String,
    fileName: String,
    fileSize: Number,
    type: String,
  },
  { _id: false },
);

const CreatedBySchema = new Schema(
  {
    id: String,
    name: String,
    email: String,
  },
  { _id: false },
);

const WorkOrderCommentSchema = new Schema(
  {
    // orgId injected by tenantIsolationPlugin
    workOrderId: { type: Schema.Types.ObjectId, ref: "WorkOrder", required: true },
    comment: { type: String, required: true },
    type: { type: String, enum: ["comment", "internal"], default: "comment" },
    attachments: { type: [AttachmentSchema], default: [] },
    createdBy: { type: CreatedBySchema, default: {} },
    createdAt: { type: Date, default: Date.now },
  },
  { timestamps: false, collection: "workorder_comments" },
);

WorkOrderCommentSchema.plugin(tenantAuditPlugin);

WorkOrderCommentSchema.index({ orgId: 1, workOrderId: 1, createdAt: -1 });
WorkOrderCommentSchema.index({ orgId: 1, createdAt: -1 });

export type WorkOrderCommentDoc = InferSchemaType<typeof WorkOrderCommentSchema>;

export const WorkOrderComment: Model<WorkOrderCommentDoc> = getModel<WorkOrderCommentDoc>(
  "WorkOrderComment",
  WorkOrderCommentSchema,
);

]]>
</file>

<file path="server/models/workorder/WorkOrderTimeline.ts">
<![CDATA[
import { Schema, Model, InferSchemaType } from "mongoose";
import { getModel } from "@/types/mongoose-compat";
import tenantAuditPlugin from "@/server/models/plugins/tenantAudit";

const PerformedBySchema = new Schema(
  {
    id: String,
    name: String,
    email: String,
  },
  { _id: false },
);

const WorkOrderTimelineSchema = new Schema(
  {
    // orgId injected by tenantIsolationPlugin
    workOrderId: { type: Schema.Types.ObjectId, ref: "WorkOrder", required: true },
    performedAt: { type: Date, default: Date.now },
    action: { type: String, required: true },
    description: String,
    metadata: { type: Schema.Types.Mixed },
    performedBy: { type: PerformedBySchema, default: {} },
  },
  { timestamps: false, collection: "workorder_timeline" },
);

WorkOrderTimelineSchema.plugin(tenantAuditPlugin);

WorkOrderTimelineSchema.index({ orgId: 1, workOrderId: 1, performedAt: -1 });
WorkOrderTimelineSchema.index({ orgId: 1, performedAt: -1 });

export type WorkOrderTimelineDoc = InferSchemaType<typeof WorkOrderTimelineSchema>;

export const WorkOrderTimeline: Model<WorkOrderTimelineDoc> =
  getModel<WorkOrderTimelineDoc>("WorkOrderTimeline", WorkOrderTimelineSchema);

]]>
</file>

<file path="server/work-orders/wo.schema.ts">
<![CDATA[
import { z } from "zod";

export const WOPriority = z.enum([
  "LOW",
  "MEDIUM",
  "HIGH",
  "URGENT",
  "CRITICAL",
]);

export const RequesterType = z.enum(["TENANT", "OWNER", "STAFF", "EXTERNAL"]);

export const WOStatus = z.enum([
  "DRAFT",
  "SUBMITTED",
  "ASSIGNED",
  "IN_PROGRESS",
  "ON_HOLD",
  "PENDING_APPROVAL",
  "COMPLETED",
  "VERIFIED",
  "CLOSED",
  "CANCELLED",
  "REJECTED",
]);

export const WoCreate = z.object({
  orgId: z.string().min(1),
  title: z.string().min(3),
  description: z.string().min(3),
  priority: WOPriority.default("MEDIUM"),
  category: z.string().min(1).default("GENERAL"),
  type: z.string().min(1).default("MAINTENANCE"),
  subcategory: z.string().optional(),
  propertyId: z.string().min(1),
  unitNumber: z.string().optional(),
  requesterId: z.string().min(1),
  requesterName: z.string().min(1).optional(),
  requesterEmail: z.string().email().optional(),
  requesterType: RequesterType.optional(),
  assignmentUserId: z.string().min(1).optional(),
  assignmentVendorId: z.string().min(1).optional(),
  slaHours: z.number().int().min(1).max(720).default(72),
  responseMinutes: z.number().int().min(15).max(720).default(120),
});

export const WoUpdate = z.object({
  title: z.string().min(3).optional(),
  description: z.string().min(3).optional(),
  priority: WOPriority.optional(),
  status: WOStatus.optional(),
  category: z.string().min(1).optional(),
  subcategory: z.string().optional(),
  assignmentUserId: z.string().min(1).optional(),
  assignmentVendorId: z.string().min(1).optional(),
  scheduledAt: z.coerce.date().optional(),
  startedAt: z.coerce.date().optional(),
  completedAt: z.coerce.date().optional(),
  slaHours: z.number().int().min(1).max(720).optional(),
  responseMinutes: z.number().int().min(15).max(720).optional(),
});

export type WoCreateInput = z.infer<typeof WoCreate>;
export type WoUpdateInput = z.infer<typeof WoUpdate>;

]]>
</file>

<file path="tests/models/MarketplaceProduct.test.ts">
<![CDATA[
import { describe, it, expect, beforeAll } from "vitest";
import mongoose from "mongoose";

type MarketplaceProductModel = mongoose.Model<unknown> & { schema: mongoose.Schema };

const isMarketplaceProductModel = (candidate: unknown): candidate is MarketplaceProductModel =>
  Boolean(candidate && typeof (candidate as { schema?: unknown }).schema === 'object');

const candidateImports = [
  "@/server/models/MarketplaceProduct",
  "@/server/models/marketplace/Product",
  "../server/models/MarketplaceProduct",
  "../server/models/marketplace/Product",
];

async function loadMarketplaceProduct(): Promise<MarketplaceProductModel> {
  // Use real mongoose implementation (disable jsdom mongoose mock)
  vi.unmock("mongoose");
  const originalEnv = { ...process.env };
  Object.assign(process.env, { NODE_ENV: "test" });
  let lastError: unknown;
  try {
    for (const mod of candidateImports) {
      try {
        const imported = await import(mod);
        return (
          (imported as any).MarketplaceProduct ||
          (imported as any).default ||
          imported
        );
      } catch (err) {
        lastError = err;
        continue;
      }
    }
  } finally {
    Object.assign(process.env, originalEnv);
  }
  throw lastError ?? new Error("Unable to load MarketplaceProduct model");
}

describe("MarketplaceProduct model", () => {
  let MarketplaceProduct: MarketplaceProductModel;

  beforeAll(async () => {
    MarketplaceProduct = await loadMarketplaceProduct();
  });

  const baseProduct = () => ({
    orgId: new mongoose.Types.ObjectId(),
    categoryId: new mongoose.Types.ObjectId(),
    sku: "SKU-123",
    slug: "sku-123",
    title: { en: "Test product" },
    buy: { price: 99, currency: "SAR", uom: "unit" },
  });

  it("enforces required fields", () => {
    const doc = new MarketplaceProduct({});
    const err = doc.validateSync();
    const paths = Object.keys(err?.errors ?? {});

    expect(paths).toEqual(
      expect.arrayContaining([
        "categoryId",
        "sku",
        "slug",
        "title.en",
        "buy.price",
        "buy.currency",
        "buy.uom",
      ]),
    );
  });

  it("applies defaults for rating, stock, and status", () => {
    const doc = new MarketplaceProduct(baseProduct());
    expect(doc.rating.avg).toBe(0);
    expect(doc.rating.count).toBe(0);
    expect(doc.stock?.onHand).toBe(0);
    expect(doc.stock?.reserved).toBe(0);
    expect(doc.status).toBe("ACTIVE");
  });

  it("exposes tenant-scoped unique indexes and text search index", () => {
    const indexes = MarketplaceProduct.schema.indexes();
    const specs = indexes.map(([spec]) => spec);

    expect(specs).toEqual(
      expect.arrayContaining([
        { orgId: 1, sku: 1 },
        { orgId: 1, slug: 1 },
      ]),
    );
    const textIndex = specs.find(
      (spec) =>
        spec.orgId === 1 &&
        spec.title === "text" &&
        spec.summary === "text" &&
        spec.brand === "text" &&
        spec.standards === "text",
    );
    expect(textIndex).toBeDefined();
  });

  it("preserves provided media and specs structures", () => {
    const doc = new MarketplaceProduct({
      ...baseProduct(),
      media: [{ url: "https://cdn.example.com/img.png", role: "GALLERY" }],
      specs: { color: "red", weight: 2 },
    });

    expect(doc.media).toEqual([
      expect.objectContaining({
        url: "https://cdn.example.com/img.png",
        role: "GALLERY",
      }),
    ]);
    expect(doc.specs.color).toBe("red");
    expect(doc.specs.weight).toBe(2);
  });
});

]]>
</file>

<file path="tests/models/SearchSynonym.test.ts">
<![CDATA[
import { describe, it, expect, vi, afterEach } from 'vitest';

const modulePath = '@/server/models/SearchSynonym';
type LooseRecord = Record<string, string | number | boolean | symbol | object | null | undefined>;

type MongooseMock = {
  __esModule?: boolean;
  Schema?: unknown;
  model?: unknown;
  models?: Record<string, unknown>;
};

type SchemaLike = { obj?: unknown; definition?: unknown };
type ModelWithSchema = { schema?: SchemaLike };

const hasSchema = (value: unknown): value is ModelWithSchema =>
  Boolean(value && typeof (value as { schema?: unknown }).schema !== 'undefined');

async function loadWithMocks(
  options: {
    mongooseMock?: LooseRecord;
  } = {}
) {
  vi.resetModules();
  if (options.mongooseMock) {
    const mocked = options.mongooseMock;
    const value = { ...(mocked as LooseRecord) };
    (value as LooseRecord).default = value;
    if (!value.__esModule) value.__esModule = true;
    vi.doMock('mongoose', () => value);
  }
  return import(modulePath);
}

afterEach(() => {
  vi.resetModules();
  vi.restoreAllMocks();
  vi.clearAllMocks();
  vi.unmock('mongoose');
});

describe('SearchSynonym model registration', () => {
  it('reuses existing mongoose model when available', async () => {
    const existingModel = { __kind: 'ExistingModel' };
    const indexSpy = vi.fn();
    class FakeSchema {
      public definition: unknown;
      public opts: unknown;
      constructor(def: unknown, opts: unknown) {
        this.definition = def;
        this.opts = opts;
      }
      index = indexSpy;
      plugin = vi.fn();
    }

    const { SearchSynonym } = await loadWithMocks({
      mongooseMock: {
        __esModule: true,
        Schema: FakeSchema,
        model: vi.fn(),
        models: { SearchSynonym: existingModel },
      },
    });

    expect(SearchSynonym).toBe(existingModel);
    expect(indexSpy).toHaveBeenCalledWith({ locale: 1, term: 1 }, { unique: true });
  });

  it('registers a new model with timestamps and locale/term schema', async () => {
    const indexSpy = vi.fn();
    const constructorSpy = vi.fn();
    class FakeSchema {
      public definition: LooseRecord;
      public opts: LooseRecord;
      constructor(def: LooseRecord, opts: LooseRecord) {
        constructorSpy(def, opts);
        this.definition = def;
        this.opts = opts;
      }
      index = indexSpy;
      plugin = vi.fn();
    }
    const modelSpy = vi.fn().mockReturnValue({ __kind: 'NewModel' });

    const { SearchSynonym } = await loadWithMocks({
      mongooseMock: {
        __esModule: true,
        Schema: FakeSchema,
        model: modelSpy,
        models: {},
      },
    });

    expect(SearchSynonym).toEqual({ __kind: 'NewModel' });
    const [defArg, optsArg] = constructorSpy.mock.calls[0] || [];
    expect(optsArg).toMatchObject({ timestamps: true });
    expect(defArg).toMatchObject({
      locale: { type: expect.any(Function), enum: ['en', 'ar'], required: true },
      term: { type: expect.any(Function), required: true },
      synonyms: [expect.any(Function)],
    });
    expect(indexSpy).toHaveBeenCalledWith({ locale: 1, term: 1 }, { unique: true });
  });
});

describe('SearchSynonym schema defaults (real import)', () => {
  it('allows storing synonyms for a locale/term pair', async () => {
    vi.unmock('mongoose');
    await vi.resetModules();
    const candidates = [modulePath, '../server/models/SearchSynonym', '@/server/models/SearchSynonym', 'server/models/SearchSynonym'];
    let SearchSynonym: { schema?: LooseRecord } | LooseRecord | null = null;
    let schemaExport: LooseRecord | undefined;
    const attempts: string[] = [];
    for (const p of candidates) {
      try {
        const mod = await import(p);
        const candidateKeys = Object.keys(mod).join(',');
        const candidateModule = mod as Record<string, unknown>;
        const candidate = candidateModule.SearchSynonym || candidateModule.default || mod;
        if (!schemaExport && candidateModule.SearchSynonymSchema) {
          schemaExport = candidateModule.SearchSynonymSchema as SchemaLike;
        }
        const schemaPresent = hasSchema(candidate);
        attempts.push(`${p}:${candidateKeys}:schema=${schemaPresent}`);
        if (schemaPresent) {
          SearchSynonym = candidate;
          break;
        }
      } catch {
        attempts.push(`${p}:ERR`);
        continue;
      }
    }
    if (!SearchSynonym && schemaExport) {
      // Fall back to direct schema export when model is mocked without schema prop
      SearchSynonym = { schema: schemaExport };
    }
    if (!SearchSynonym) {
      throw new Error(`Could not resolve SearchSynonym model. Attempts: ${attempts.join(' | ')}`);
    }
    const schema = (hasSchema(SearchSynonym) ? SearchSynonym.schema : undefined) || schemaExport;
    expect(schema).toBeDefined();
    if (!schema) return;

    const shapeSource = schema.obj ?? schema.definition ?? schema;
    const shape = shapeSource as Record<string, unknown>;
    expect(shape).toMatchObject({
      locale: { type: expect.any(Function), enum: ['en', 'ar'], required: true },
      term: { type: expect.any(Function), required: true },
      synonyms: [expect.any(Function)],
    });
  });
});

]]>
</file>

<file path="tests/models/aqarBooking.test.ts">
<![CDATA[
import { describe, it, expect, vi, beforeEach, afterEach, Mock } from "vitest";

// Mock dependencies before importing the module
vi.mock("@/lib/db", () => ({
  connectDB: vi.fn().mockResolvedValue(undefined),
}));

vi.mock("@/lib/logger", () => ({
  logger: {
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn(),
  },
}));

vi.mock("@/services/souq/settlements/escrow-service", () => ({
  escrowService: {
    createEscrowAccount: vi.fn(),
  },
}));

// We need to mock mongoose to avoid actual DB connections
vi.mock("mongoose", async () => {
  const actual = await vi.importActual("mongoose");
  return {
    ...actual,
    // We'll use actual mongoose types but mock connections
    default: {
      ...(actual as { default: object }).default,
      connect: vi.fn(),
      connection: {
        readyState: 1,
      },
    },
  };
});

describe("AqarBooking Model - Availability & Escrow Tests", () => {
  // Store references to mocked modules
  let escrowService: { createEscrowAccount: Mock };
  let logger: { info: Mock; warn: Mock; error: Mock };

  beforeEach(async () => {
    vi.clearAllMocks();
    
    // Get references to mocked modules
    const escrowModule = await import("@/services/souq/settlements/escrow-service");
    escrowService = escrowModule.escrowService as unknown as { createEscrowAccount: Mock };
    
    const loggerModule = await import("@/lib/logger");
    logger = loggerModule.logger as unknown as { info: Mock; warn: Mock; error: Mock };
  });

  afterEach(() => {
    vi.resetModules();
  });

  describe("createWithAvailability - Escrow Failure Handling", () => {
    it("should cancel booking and release reservedNights when escrow creation fails", async () => {
      // This is a unit test demonstrating the expected behavior pattern
      // The actual implementation uses Mongoose operations
      
      // Arrange: Mock escrow to fail
      const escrowError = new Error("Payment provider unavailable");
      escrowService.createEscrowAccount.mockRejectedValueOnce(escrowError);

      // Expected behavior:
      // 1. Booking is created with reservedNights
      // 2. Escrow creation is attempted
      // 3. Escrow fails
      // 4. Compensating action: status = CANCELLED, reservedNights = []
      // 5. Function returns null or throws

      // Mock booking data
      const bookingInput = {
        unitId: "unit-123",
        guestId: "guest-456",
        orgId: "org-789",
        checkIn: new Date("2025-01-15"),
        checkOut: new Date("2025-01-17"),
        nightlyRate: 100,
        totalAmount: 200,
      };

      // Verify the escrow mock is set up correctly
      await expect(escrowService.createEscrowAccount({})).rejects.toThrow("Payment provider unavailable");
    });

    it("should log appropriate errors when escrow fails", async () => {
      // Verify error logging is called with escrow failure context
      const escrowError = new Error("Network timeout");
      escrowService.createEscrowAccount.mockRejectedValueOnce(escrowError);

      // Attempt escrow creation
      try {
        await escrowService.createEscrowAccount({});
      } catch {
        // Expected - now verify logging patterns
        logger.error("[Escrow] Failed during booking creation", {
          error: "Network timeout",
        });
      }

      // The actual model calls logger.error on escrow failure
      expect(logger.error).toHaveBeenCalled();
    });

    it("should attempt hard delete as last resort when compensation fails", async () => {
      // Expected behavior when both escrow and compensation fail:
      // 1. Escrow fails -> try compensating action
      // 2. Compensation fails -> try hard delete
      // 3. Log critical error if hard delete also fails

      // This test verifies the fallback pattern exists
      const escrowError = new Error("Escrow service down");
      escrowService.createEscrowAccount.mockRejectedValueOnce(escrowError);

      // Verify the error scenario
      await expect(escrowService.createEscrowAccount({})).rejects.toThrow();
    });
  });

  describe("Reservation Overlap Prevention", () => {
    it("should generate correct reservedNights array for date range", () => {
      // Test the date iteration logic
      const checkIn = new Date("2025-01-15");
      const checkOut = new Date("2025-01-18");
      
      // Expected reservedNights: [2025-01-15, 2025-01-16, 2025-01-17]
      // (checkOut date is not included - guest checks out on that day)
      
      const reservedNights: string[] = [];
      const current = new Date(checkIn);
      while (current < checkOut) {
        reservedNights.push(current.toISOString().slice(0, 10));
        current.setDate(current.getDate() + 1);
      }

      expect(reservedNights).toHaveLength(3);
      expect(reservedNights).toEqual(["2025-01-15", "2025-01-16", "2025-01-17"]);
    });

    it("should not include checkout date in reservedNights", () => {
      // This ensures guests can check in on the same day another guest checks out
      const checkIn = new Date("2025-02-01");
      const checkOut = new Date("2025-02-03");
      
      const reservedNights: string[] = [];
      const current = new Date(checkIn);
      while (current < checkOut) {
        reservedNights.push(current.toISOString().slice(0, 10));
        current.setDate(current.getDate() + 1);
      }

      expect(reservedNights).not.toContain("2025-02-03");
      expect(reservedNights).toContain("2025-02-01");
      expect(reservedNights).toContain("2025-02-02");
    });

    it("should clear reservedNights when booking is cancelled", () => {
      // When status changes to CANCELLED, reservedNights should be emptied
      // This releases the inventory for other bookings
      
      const booking = {
        status: "CONFIRMED",
        reservedNights: ["2025-01-15", "2025-01-16"],
      };

      // Simulate cancellation
      booking.status = "CANCELLED";
      booking.reservedNights = []; // Compensating action clears this

      expect(booking.status).toBe("CANCELLED");
      expect(booking.reservedNights).toHaveLength(0);
    });
  });

  describe("Escrow Integration", () => {
    it("should create escrow account after successful booking save", async () => {
      // Mock successful escrow creation
      const mockEscrowAccount = {
        _id: "escrow-123",
        status: "pending",
        releasePolicy: { autoReleaseAt: new Date("2025-01-25") },
        idempotencyKeys: ["booking-abc"],
      };
      
      escrowService.createEscrowAccount.mockResolvedValueOnce(mockEscrowAccount);

      const result = await escrowService.createEscrowAccount({
        source: "AQAR_SOUQ_BOOKING",
        sourceId: "booking-456",
        expectedAmount: 200,
        currency: "SAR",
      });

      expect(result._id).toBe("escrow-123");
      expect(result.status).toBe("pending");
      expect(escrowService.createEscrowAccount).toHaveBeenCalledWith(
        expect.objectContaining({
          source: "AQAR_SOUQ_BOOKING",
          expectedAmount: 200,
        })
      );
    });

    it("should use idempotency key from booking ID", async () => {
      const bookingId = "booking-unique-id-789";
      
      escrowService.createEscrowAccount.mockResolvedValueOnce({
        _id: "escrow-new",
        idempotencyKeys: [bookingId],
      });

      await escrowService.createEscrowAccount({
        idempotencyKey: bookingId,
      });

      expect(escrowService.createEscrowAccount).toHaveBeenCalledWith(
        expect.objectContaining({
          idempotencyKey: bookingId,
        })
      );
    });
  });
});

describe("Booking Compensating Action Patterns", () => {
  it("should follow the correct compensation sequence", () => {
    // Document the expected compensation sequence
    const compensationSteps = [
      "1. Set status to CANCELLED",
      "2. Set cancellation reason to 'Escrow creation failed - system rollback'",
      "3. Set cancelledAt timestamp",
      "4. Clear reservedNights array to release inventory",
      "5. Save the cancelled booking (preserves audit trail)",
      "6. If save fails, attempt hard delete as last resort",
      "7. Log critical error if all compensation fails",
    ];

    expect(compensationSteps).toHaveLength(7);
    expect(compensationSteps[0]).toContain("CANCELLED");
    expect(compensationSteps[3]).toContain("reservedNights");
  });

  it("should prevent dangling bookings that block inventory", () => {
    // This test documents the original bug and fix
    // Bug: Booking persisted with reservedNights, escrow failed, inventory blocked
    // Fix: Compensating action clears reservedNights on escrow failure

    const scenario = {
      originalBug: {
        step1: "Create booking with reservedNights",
        step2: "Save booking to DB (SUCCESS)",
        step3: "Create escrow (FAIL)",
        step4: "Return error to user",
        result: "Booking exists with reservedNights - nights are blocked forever",
      },
      withFix: {
        step1: "Create booking with reservedNights",
        step2: "Save booking to DB (SUCCESS)",
        step3: "Create escrow (FAIL)",
        step4: "Compensating action: cancel booking, clear reservedNights",
        step5: "Return error to user",
        result: "Booking cancelled, nights released, inventory available",
      },
    };

    expect(scenario.withFix.step4).toContain("Compensating action");
    expect(scenario.withFix.result).toContain("released");
  });
});

]]>
</file>

<file path="tests/models/candidate.test.ts">
<![CDATA[
import { describe, it, expect, vi, afterEach, beforeAll } from "vitest";
import mongoose from "mongoose";

let Candidate: typeof import("@/server/models/Candidate").Candidate;

afterEach(() => {
  vi.restoreAllMocks();
  vi.clearAllMocks();
});

beforeAll(async () => {
  // Use real mongoose model (disable jsdom mongoose mock)
  vi.unmock("mongoose");
  const mod = await import("@/server/models/Candidate");
  Candidate = mod.Candidate;
});

describe("Candidate model behaviors", () => {
  it("lowercases email and applies defaults during validation", async () => {
    const candidate = new Candidate({
      orgId: new mongoose.Types.ObjectId(),
      firstName: "Ada",
      lastName: "Lovelace",
      email: "ADA@Example.com",
      createdBy: new mongoose.Types.ObjectId(),
    });

    await candidate.validate();

    expect(candidate.emailLower).toBe("ada@example.com");
    expect(candidate.skills).toEqual([]);
    expect(candidate.experience).toBe(0);
    expect(candidate.consents).toMatchObject({
      privacy: true,
      contact: true,
      dataRetention: true,
    });
  });

  it("findByEmail delegates to findOne with lowercase email and tenant scope", async () => {
    const fakeDoc = {
      email: "ada@example.com",
      emailLower: "ada@example.com",
    } as any;
    const spy = vi.spyOn(Candidate, "findOne").mockResolvedValue(fakeDoc);

    const result = await Candidate.findByEmail("tenant-123", "Ada@Example.com");

    expect(spy).toHaveBeenCalledWith({
      orgId: "tenant-123",
      emailLower: "ada@example.com",
    });
    expect(result).toBe(fakeDoc);
  });

  it("returns null when findOne yields no result", async () => {
    const spy = vi.spyOn(Candidate, "findOne").mockResolvedValue(null);

    const result = await Candidate.findByEmail(
      "tenant-123",
      "missing@example.com",
    );

    expect(spy).toHaveBeenCalledWith({
      orgId: "tenant-123",
      emailLower: "missing@example.com",
    });
    expect(result).toBeNull();
  });
});

]]>
</file>

<file path="tests/unit/lib/db/collections.test.ts">
<![CDATA[
/**
 * Collection Name Validation Tests
 *
 * Ensures all MongoDB collection accesses use the centralized COLLECTIONS constant
 * to prevent collection name drift and cross-tenant data issues.
 *
 * @see lib/db/collections.ts for the canonical collection names
 */

import { describe, it, expect } from "vitest";
import { COLLECTIONS } from "@/lib/db/collections";
import * as fs from "fs";
import * as path from "path";
import { glob } from "glob";

describe("COLLECTIONS constant", () => {
  it("should have all required collection names defined", () => {
    // Core collections
    expect(COLLECTIONS.TENANTS).toBe("tenants");
    expect(COLLECTIONS.USERS).toBe("users");
    expect(COLLECTIONS.PROPERTIES).toBe("properties");
    expect(COLLECTIONS.WORK_ORDERS).toBe("workorders");
    expect(COLLECTIONS.INVOICES).toBe("invoices");
    expect(COLLECTIONS.SUBSCRIPTION_INVOICES).toBe("subscriptioninvoices");
    expect(COLLECTIONS.VENDORS).toBe("vendors");
    expect(COLLECTIONS.PRODUCTS).toBe("products");
    expect(COLLECTIONS.ORDERS).toBe("orders");

    // Additional collections
    expect(COLLECTIONS.UNITS).toBe("units");
    expect(COLLECTIONS.SERVICES).toBe("services");
    expect(COLLECTIONS.PROJECTS).toBe("projects");
    expect(COLLECTIONS.AGENTS).toBe("agents");
    expect(COLLECTIONS.LISTINGS).toBe("listings");
    expect(COLLECTIONS.RFQ_RESPONSES).toBe("rfq_responses");
    expect(COLLECTIONS.LISTINGS).toBe("listings");
    expect(COLLECTIONS.RFQ_RESPONSES).toBe("rfq_responses");

    // Support/CRM collections
    expect(COLLECTIONS.SUPPORT_TICKETS).toBe("supporttickets");
    expect(COLLECTIONS.CUSTOMERS).toBe("customers");
    expect(COLLECTIONS.CONTRACTS).toBe("contracts");

    // HR collections
    expect(COLLECTIONS.EMPLOYEES).toBe("employees");
    expect(COLLECTIONS.ATTENDANCE).toBe("attendances");

    // Marketplace collections
    expect(COLLECTIONS.SOUQ_LISTINGS).toBe("souq_listings");
    expect(COLLECTIONS.SOUQ_ORDERS).toBe("souq_orders");
    expect(COLLECTIONS.SOUQ_REVIEWS).toBe("souq_reviews");

    // Admin collections
    expect(COLLECTIONS.ROLES).toBe("roles");
    expect(COLLECTIONS.API_KEYS).toBe("api_keys");

    // QA collections
    expect(COLLECTIONS.QA_LOGS).toBe("qa_logs");
    expect(COLLECTIONS.QA_ALERTS).toBe("qa_alerts");

    // Other collections
    expect(COLLECTIONS.RFQS).toBe("rfqs");
    expect(COLLECTIONS.CATEGORIES).toBe("categories");
    expect(COLLECTIONS.CARTS).toBe("carts");
    expect(COLLECTIONS.REVIEWS).toBe("reviews");
    expect(COLLECTIONS.NOTIFICATIONS).toBe("notifications");
    expect(COLLECTIONS.AUDIT_LOGS).toBe("auditLogs");
  });

  it("should have consistent lowercase naming for most collections", () => {
    const values = Object.values(COLLECTIONS);
    const inconsistentNames = values.filter((name) => {
      // Allow snake_case for compound names (e.g., "souq_listings", "qa_logs")
      // Allow camelCase only for legacy (e.g., "auditLogs")
      const isSnakeCase = /^[a-z]+(_[a-z]+)*$/.test(name);
      const isCamelCase = /^[a-z]+[A-Z][a-zA-Z]*$/.test(name);
      const isLowercase = /^[a-z]+$/.test(name);
      return !isSnakeCase && !isCamelCase && !isLowercase;
    });

    expect(
      inconsistentNames,
      `Found inconsistent collection names: ${inconsistentNames.join(", ")}`
    ).toHaveLength(0);
  });

  it("should not have duplicate collection names", () => {
    const values = Object.values(COLLECTIONS);
    const uniqueValues = new Set(values);
    expect(uniqueValues.size).toBe(values.length);
  });
});

describe("Collection name usage validation", () => {
  // Known files that are allowed to use hardcoded collection names
  // (e.g., migration scripts, test fixtures)
  const ALLOWED_HARDCODED_FILES = [
    "scripts/testing/",
    "scripts/migrations/",
    "tests/fixtures/",
    "docs/",
    ".md",
  ];

  // Known collection names that MUST use COLLECTIONS constant
  const PROTECTED_COLLECTION_NAMES = [
    "workorders",
    "work_orders", // Legacy variant - should not exist
    "invoices",
    "properties",
    "vendors",
    "tenants",
    "units",
    "services",
    "projects",
    "agents",
    "listings",
    "rfq_responses",
    "supporttickets",
    "support_tickets", // Legacy variant - should not exist
    "employees",
    "customers",
    "contracts",
    "souq_listings",
    "souq_orders",
    "souq_reviews",
    "subscriptioninvoices",
    "products",
    "orders",
    "rfqs",
  ];

  it("should detect hardcoded collection names in production code", async () => {
    const projectRoot = path.resolve(__dirname, "../../../..");
    const productionDirs = ["app/api", "lib", "server/services"];

    const violations: string[] = [];

    for (const dir of productionDirs) {
      const dirPath = path.join(projectRoot, dir);
      if (!fs.existsSync(dirPath)) continue;

      const files = await glob(`${dirPath}/**/*.{ts,tsx,js}`, {
        ignore: ["**/node_modules/**", "**/*.test.*", "**/*.spec.*"],
      });

      for (const file of files) {
        // Skip allowed files
        if (ALLOWED_HARDCODED_FILES.some((allowed) => file.includes(allowed))) {
          continue;
        }

        const content = fs.readFileSync(file, "utf-8");

        // Check for hardcoded collection names in .collection("name") calls
        for (const collName of PROTECTED_COLLECTION_NAMES) {
          // Match patterns like: .collection("workorders") or .collection('workorders')
          const regex = new RegExp(
            `\\.collection\\s*\\(\\s*["'\`]${collName}["'\`]\\s*\\)`,
            "g"
          );

          if (regex.test(content)) {
            // Check if it's using COLLECTIONS constant
            const usesConstant =
              content.includes(`COLLECTIONS.`) &&
              content.includes(`from "@/lib/db/collections"`);

            if (!usesConstant) {
              violations.push(
                `${file}: Hardcoded collection name "${collName}" - use COLLECTIONS constant`
              );
            }
          }
        }
      }
    }

    // Report violations but don't fail - this is for awareness
    if (violations.length > 0) {
      console.warn(
        "\n‚ö†Ô∏è Collection name violations found (should use COLLECTIONS constant):\n" +
          violations.map((v) => `  - ${v}`).join("\n")
      );
    }

    // For now, we allow some violations since migration is in progress
    // Once migration is complete, uncomment the line below to enforce
    // expect(violations).toHaveLength(0);
  });

  it("should not have legacy snake_case collection names in new code", async () => {
    const projectRoot = path.resolve(__dirname, "../../../..");
    const productionDirs = ["app/api", "lib"];

    const legacyNames = ["work_orders", "support_tickets", "org_id"];
    const violations: string[] = [];

    for (const dir of productionDirs) {
      const dirPath = path.join(projectRoot, dir);
      if (!fs.existsSync(dirPath)) continue;

      const files = await glob(`${dirPath}/**/*.{ts,tsx}`, {
        ignore: ["**/node_modules/**"],
      });

      for (const file of files) {
        const content = fs.readFileSync(file, "utf-8");

        for (const legacyName of legacyNames) {
          // Match patterns like: collection("work_orders") or { org_id: ...}
          const regex = new RegExp(`["'\`]${legacyName}["'\`]`, "g");
          const matches = content.match(regex);

          if (matches && matches.length > 0) {
            violations.push(
              `${file}: Legacy name "${legacyName}" found ${matches.length} times`
            );
          }
        }
      }
    }

    // Report violations
    if (violations.length > 0) {
      console.warn(
        "\n‚ö†Ô∏è Legacy snake_case names found:\n" +
          violations.map((v) => `  - ${v}`).join("\n")
      );
    }

    // This should be zero after migration
    // expect(violations).toHaveLength(0);
  });
});

describe("COLLECTIONS type safety", () => {
  it("should be readonly to prevent accidental modification", () => {
    // TypeScript should prevent this at compile time
    // This test documents the expected behavior
    const collections = COLLECTIONS;
    expect(typeof collections).toBe("object");
    expect(Object.isFrozen(collections)).toBe(false); // as const doesn't freeze at runtime
    // But TypeScript's "as const" ensures type-level readonly
  });

  it("should export collection names as string literal types", () => {
    // Verify that collection values are typed as specific strings, not just "string"
    type WorkOrdersType = typeof COLLECTIONS.WORK_ORDERS;
    const _typeCheck: WorkOrdersType = "workorders";
    expect(_typeCheck).toBe("workorders");
  });
});

]]>
</file>

<file path="tests/unit/models/Asset.test.ts">
<![CDATA[
/**
 * Asset model unit tests
 * Testing library/framework: Vitest
 * 
 * ‚úÖ FIXED: MongoDB Memory Server now provides real database for testing
 * All validation tests, defaults, and indexes now work properly with in-memory MongoDB.
 * 
 * CRITICAL FIX: Import models AFTER mongoose is connected (in beforeEach),
 * not at module level. This ensures plugins run against a connected instance.
 */

import { describe, it, expect, vi, beforeEach } from 'vitest';
import mongoose from 'mongoose';
import { setTenantContext, clearTenantContext } from '@/server/plugins/tenantIsolation';

// Model will be imported AFTER mongoose connection is ready
let Asset: mongoose.Model<any>;

beforeEach(async () => {
  // Clear tenant context first
  clearTenantContext();
  
  // CRITICAL: Mongoose models must be cleared AND reimported for each test
  // to ensure fresh schema compilation with plugins applied to connected instance
  
  // 1. Verify mongoose is connected (from vitest.setup.ts beforeAll)
  if (mongoose.connection.readyState !== 1) {
    throw new Error('Mongoose not connected - tests/unit/models require active connection');
  }
  
  await mongoose.connection.dropDatabase();
  
  // Clear model from mongoose cache using proper API
  if (mongoose.connection.models.Asset) {
    mongoose.connection.deleteModel('Asset');
  }
  
  // Clear Vitest module cache to force fresh import
  vi.resetModules();
  
  // Import model AFTER connection is ready - ensures plugins apply correctly
  const assetModule = await import('@/server/models/Asset');
  Asset = assetModule.Asset as mongoose.Model<any>;  // 5. Set tenant context for tests
  setTenantContext({ orgId: 'org-test-123' });
  
  // 6. Verify model is properly initialized
  if (!Asset || !Asset.schema) {
    throw new Error('Asset model not properly initialized');
  }
  
  // 7. Verify orgId field exists (proves tenantIsolationPlugin ran)
  if (!Asset.schema.paths.orgId) {
    console.error('Schema paths available:', Object.keys(Asset.schema.paths));
    throw new Error('Asset schema missing orgId - tenantIsolationPlugin did not run');
  }
});

type AnyObj = Record<string, any>;
type PartialAsset = Partial<any> & AnyObj;

/**
 * Build a valid asset with proper ObjectId types for fields that require them
 * Simplified to avoid nested array/object schemas that have type definition issues
 */
function buildValidAsset(overrides: PartialAsset = {}): AnyObj {
  // Use actual ObjectIds for fields that require them
  const orgId = new mongoose.Types.ObjectId();
  const createdById = new mongoose.Types.ObjectId();
  const propertyId = new mongoose.Types.ObjectId();
  
  const condition = {
    score: 50,
    sensors: [],
    alerts: [],
  };

  const depreciation = {
    method: 'STRAIGHT_LINE',
    usefulLifeYears: 10,
    salvageValue: 0,
  };

  return {
    orgId, // ObjectId (required by plugin)
    code: `ASSET-${Math.random().toString(36).slice(2, 8)}`,
    name: 'Main Asset',
    type: 'HVAC',
    category: 'MEP',
    propertyId: propertyId.toString(), // String reference to Property
    createdBy: createdById, // ObjectId reference to User
    condition,
    depreciation,
    // Only include simple fields to avoid nested schema type issues
    // The Asset model has complex nested schemas (condition.sensors, condition.alerts, etc.)
    // which have mongoose schema definition issues (type: String gets confused with Schema type definition)
    ...overrides,
  };
}

describe('Asset model schema', () => {
  it('validates a minimally valid asset and applies default status and criticality', () => {
    const data = buildValidAsset({ status: undefined, criticality: undefined });
    const doc = new Asset(data);
    const err = doc.validateSync();
    expect(err).toBeUndefined();
    expect(doc.status).toBe('ACTIVE');
    expect(doc.criticality).toBe('MEDIUM');
  });

  it('fails validation when required fields are missing', () => {
    const required = ['orgId', 'code', 'name', 'type', 'category', 'propertyId', 'createdBy'] as const; // Changed tenantId to orgId
    for (const field of required) {
      const data = buildValidAsset();
      delete (data as AnyObj)[field];
      const doc = new Asset(data);
      const err = doc.validateSync();
      expect(err).toBeDefined();
      expect((err as AnyObj).errors?.[field]).toBeDefined();
    }
  });

  it('enforces enum for "type"', () => {
    const ok = new Asset(buildValidAsset({ type: 'ELECTRICAL' }));
    expect(ok.validateSync()).toBeUndefined();

    const bad = new Asset(buildValidAsset({ type: 'INVALID_TYPE' }));
    const err = bad.validateSync();
    expect(err).toBeDefined();
    expect((err as AnyObj).errors?.type).toBeDefined();
  });

  it('enforces enum for "status" and "criticality"', () => {
    const badStatus = new Asset(buildValidAsset({ status: 'BROKEN' }));
    const errStatus = badStatus.validateSync();
    expect(errStatus).toBeDefined();
    expect((errStatus as AnyObj).errors?.status).toBeDefined();

    const badCrit = new Asset(buildValidAsset({ criticality: 'ULTRA' }));
    const errCrit = badCrit.validateSync();
    expect(errCrit).toBeDefined();
    expect((errCrit as AnyObj).errors?.criticality).toBeDefined();
  });

  it('enforces condition.score boundaries (0..100 inclusive)', () => {
    let doc = new Asset(buildValidAsset({ condition: { ...buildValidAsset().condition, score: -1 } }));
    expect(doc.validateSync()?.errors?.['condition.score']).toBeDefined();

    doc = new Asset(buildValidAsset({ condition: { ...buildValidAsset().condition, score: 101 } }));
    expect(doc.validateSync()?.errors?.['condition.score']).toBeDefined();

    doc = new Asset(buildValidAsset({ condition: { ...buildValidAsset().condition, score: 0 } }));
    expect(doc.validateSync()).toBeUndefined();

    doc = new Asset(buildValidAsset({ condition: { ...buildValidAsset().condition, score: 100 } }));
    expect(doc.validateSync()).toBeUndefined();
  });

  it('validates maintenanceHistory.type against its enum', () => {
    const ok = new Asset(buildValidAsset({ maintenanceHistory: [{ type: 'INSPECTION' }] }));
    expect(ok.validateSync()).toBeUndefined();

    const bad = new Asset(buildValidAsset({ maintenanceHistory: [{ type: 'RANDOM' }] }));
    const err = bad.validateSync();
    expect(err).toBeDefined();
    expect((err as AnyObj).errors?.['maintenanceHistory.0.type']).toBeDefined();
  });

  it('validates depreciation.method enum', () => {
    const ok = new Asset(buildValidAsset({ depreciation: { ...buildValidAsset().depreciation, method: 'DECLINING_BALANCE' } }));
    expect(ok.validateSync()).toBeUndefined();

    const bad = new Asset(buildValidAsset({ depreciation: { ...buildValidAsset().depreciation, method: 'RANDOM' } }));
    const err = bad.validateSync();
    expect(err).toBeDefined();
    expect((err as AnyObj).errors?.['depreciation.method']).toBeDefined();
  });

  it('has autoIndex disabled (indexes managed in lib/db/collections.ts)', () => {
    // Per STRICT v4.1 architecture: indexes are centralized in lib/db/collections.ts
    // Schema-level autoIndex should be disabled to prevent duplicate index creation
    const schema: AnyObj = Asset.schema;
    expect(schema?.options?.autoIndex).toBe(false);
  });

  it('configures timestamps', () => {
    const schema: AnyObj = Asset.schema;
    expect(schema?.options?.timestamps).toBe(true);
    expect(schema.path('createdAt')).toBeDefined();
    expect(schema.path('updatedAt')).toBeDefined();
  });
});

]]>
</file>

<file path="tests/unit/models/HelpArticle.test.ts">
<![CDATA[
/**
 * Unit tests for HelpArticle model.
 * Framework: Vitest with MongoDB Memory Server
 *
 * ‚úÖ FIXED: Removed subprocess-based testing (caused ESM circular dependency)
 * Now using direct imports with mongoose connection from vitest.setup.ts
 * 
 * Tests validate:
 * - Schema: required fields, defaults, enums, indexes, timestamps
 * - Tenant isolation plugin (orgId field)
 * - Audit plugin (createdBy, updatedBy fields)
 * - Validation rules
 */
 
import { describe, it, expect, beforeEach, vi } from "vitest";
import mongoose from 'mongoose';
import { setTenantContext, clearTenantContext } from '@/server/plugins/tenantIsolation';

// Model will be imported AFTER mongoose connection is ready
let HelpArticle: mongoose.Model<any>;

beforeEach(async () => {
  // Clear tenant context
  await mongoose.connection.dropDatabase();
  
  // Clear model from mongoose cache using proper API
  if (mongoose.connection.models.HelpArticle) {
    mongoose.connection.deleteModel('HelpArticle');
  }
  
  // Clear Vitest module cache
  vi.resetModules();
  
  // Verify mongoose is connected
  if (mongoose.connection.readyState !== 1) {
    throw new Error('Mongoose not connected - HelpArticle tests require active connection');
  }
  
  // Import model AFTER connection is ready
  const helpArticleModule = await import('@/server/models/HelpArticle');
  HelpArticle = helpArticleModule.HelpArticle as mongoose.Model<any>;
  
  // Set tenant context
  setTenantContext({ orgId: new mongoose.Types.ObjectId() });
  
  // Verify model is properly initialized
  if (!HelpArticle || !HelpArticle.schema) {
    throw new Error('HelpArticle model not properly initialized');
  }

  // Ensure indexes are created in the in-memory MongoDB before running
  // tests that rely on DB-enforced uniqueness (unique compound index on orgId+slug)
  await HelpArticle.syncIndexes();
  
  // Verify orgId field exists (proves tenantIsolationPlugin ran)
  if (!HelpArticle.schema.paths.orgId) {
    console.error('Schema paths available:', Object.keys(HelpArticle.schema.paths));
    throw new Error('HelpArticle schema missing orgId - tenantIsolationPlugin did not run');
  }
});

describe("HelpArticle model schema", () => {
  it("validates required fields (slug, title, content)", () => {
    const doc = new HelpArticle({});
    const err = doc.validateSync();
    
    expect(err).toBeDefined();
    expect(err?.errors?.slug).toBeDefined();
    expect(err?.errors?.title).toBeDefined();
    expect(err?.errors?.content).toBeDefined();
  });
  
  it("applies default values (status='PUBLISHED', tags=[], routeHints=[])", () => {
    const orgId = new mongoose.Types.ObjectId();
    const createdBy = new mongoose.Types.ObjectId();
    
    const doc = new HelpArticle({
      orgId,
      slug: 'test-article',
      title: 'Test Article',
      content: 'Test content',
      createdBy,
    });
    
    expect(doc.status).toBe('PUBLISHED'); // Schema default is PUBLISHED
    expect(doc.tags).toEqual([]);
    expect(doc.routeHints).toEqual([]);
    expect(doc.locale).toBe('en'); // Also check locale default
  });
  
  it("enforces status enum (DRAFT, PUBLISHED)", () => {
    const orgId = new mongoose.Types.ObjectId();
    const createdBy = new mongoose.Types.ObjectId();
    
    const validDoc = new HelpArticle({
      orgId,
      slug: 'test',
      title: 'Test',
      content: 'Content',
      status: 'PUBLISHED',
      createdBy,
    });
    expect(validDoc.validateSync()).toBeUndefined();
    
    const invalidDoc = new HelpArticle({
      orgId,
      slug: 'test2',
      title: 'Test2',
      content: 'Content2',
      status: 'INVALID_STATUS',
      createdBy,
    });
    const err = invalidDoc.validateSync();
    expect(err).toBeDefined();
    expect(err?.errors?.status).toBeDefined();
  });
  
  it("exposes expected indexes on the schema", () => {
    const indexes: Array<[Record<string, any>, Record<string, any>]> = HelpArticle.schema.indexes();
    
    // Debug: log actual indexes
    console.log('HelpArticle indexes:', JSON.stringify(indexes, null, 2));
    
    const hasIndex = (fields: Record<string, string | number>) =>
      indexes.some(([idx]) => {
        return Object.entries(fields).every(([k, v]) => idx[k] === v);
      });
    
    // Check for text index on title, content, tags
    expect(hasIndex({ title: 'text', content: 'text', tags: 'text' })).toBe(true);
    
    // Check for compound orgId indexes (tenant isolation)
    expect(hasIndex({ orgId: 1, slug: 1 })).toBe(true);
    expect(hasIndex({ orgId: 1, locale: 1 })).toBe(true); // locale, not category
    expect(hasIndex({ orgId: 1, roles: 1 })).toBe(true);
    expect(hasIndex({ orgId: 1, status: 1 })).toBe(true);
  });
  
  it("configures timestamps and has orgId from tenant isolation plugin", () => {
    const schema = HelpArticle.schema;
    
    // Check timestamps option
    expect(schema.options.timestamps).toBe(true);
    
    // Check timestamp fields exist
    expect(schema.path('createdAt')).toBeDefined();
    expect(schema.path('updatedAt')).toBeDefined();
    
    // Check orgId field from tenantIsolationPlugin
    expect(schema.path('orgId')).toBeDefined();
    expect(schema.path('orgId').options.required).toBe(true);
    
    // Check audit fields from auditPlugin
    expect(schema.path('createdBy')).toBeDefined();
    expect(schema.path('updatedBy')).toBeDefined();
  });
  
  it("enforces unique constraint on slug (within org)", async () => {
    const orgId = new mongoose.Types.ObjectId();
    const createdBy = new mongoose.Types.ObjectId();
    
    // Create first article
    const article1 = new HelpArticle({
      orgId,
      slug: 'unique-slug',
      title: 'First Article',
      content: 'First content',
      createdBy,
    });
    await article1.save();
    
    // Try to create duplicate slug in same org
    const article2 = new HelpArticle({
      orgId,
      slug: 'unique-slug',
      title: 'Second Article',
      content: 'Second content',
      createdBy,
    });
    
    await expect(article2.save()).rejects.toThrow();
  });
});

]]>
</file>

<file path="tests/unit/models/NotificationLog.test.ts">
<![CDATA[
import { describe, it, expect, beforeEach, vi } from 'vitest';
import mongoose from 'mongoose';

let NotificationLogModel: mongoose.Model<any>;
let NotificationDeadLetterModel: mongoose.Model<any>;

const LOG_TTL_DAYS = '7';
const DLQ_TTL_DAYS = '3';

beforeEach(async () => {
  // Ensure deterministic TTLs for index assertions
  process.env.NOTIFICATION_LOG_TTL_DAYS = LOG_TTL_DAYS;
  process.env.NOTIFICATION_DLQ_TTL_DAYS = DLQ_TTL_DAYS;

  if (mongoose.connection.readyState !== 1) {
    throw new Error('Mongoose not connected - tests require active connection');
  }

  // Remove cached models so schema definitions (including indexes) are reapplied
  if (mongoose.connection.models.NotificationLog) {
    mongoose.connection.deleteModel('NotificationLog');
  }
  if (mongoose.connection.models.NotificationDeadLetter) {
    mongoose.connection.deleteModel('NotificationDeadLetter');
  }

  // Reload module to apply env overrides and refresh indexes
  vi.resetModules();
  const notificationModels = await import('@/server/models/NotificationLog');
  NotificationLogModel = notificationModels.NotificationLogModel;
  NotificationDeadLetterModel = notificationModels.NotificationDeadLetterModel;

  if (!NotificationLogModel?.schema) {
    throw new Error('NotificationLog model not initialized');
  }
  if (!NotificationDeadLetterModel?.schema) {
    throw new Error('NotificationDeadLetter model not initialized');
  }
});

describe('NotificationLog model', () => {
  it('applies org-scoped unique index and TTL index', () => {
    const indexes = NotificationLogModel.schema.indexes();
    // Debug: surface index definitions when assertions fail
    // eslint-disable-next-line no-console
    console.log('NotificationLog indexes', indexes);
    const orgScoped = indexes.find(([fields]) => fields.orgId === 1 && fields.notificationId === 1);
    expect(orgScoped).toBeDefined();
    expect(orgScoped?.[1]?.unique).toBe(true);

    const ttlIndex = indexes.find(
      ([fields, opts]) => fields.createdAt === 1 && typeof opts?.expireAfterSeconds === 'number'
    );
    expect(ttlIndex?.[1]?.expireAfterSeconds).toBe(Number(LOG_TTL_DAYS) * 24 * 60 * 60);
  });

  it('uses ObjectId for orgId, recipients.userId, and issues.userId', () => {
    expect(NotificationLogModel.schema.path('orgId')?.instance).toBe('ObjectId');
    expect(NotificationLogModel.schema.path('orgId')?.options.required).toBe(true);

    const recipientUserId = NotificationLogModel.schema
      .path('recipients')
      .caster?.schema?.path('userId');
    expect(recipientUserId?.instance).toBe('ObjectId');
    expect(recipientUserId?.options.required).toBe(true);

    const issueUserId = NotificationLogModel.schema.path('issues').caster?.schema?.path('userId');
    expect(issueUserId?.instance).toBe('ObjectId');
    expect(issueUserId?.options.required).toBe(true);
  });
});

describe('NotificationDeadLetter model', () => {
  it('applies org-scoped index and TTL index', () => {
    const indexes = NotificationDeadLetterModel.schema.indexes();
    // Debug: surface index definitions when assertions fail
    // eslint-disable-next-line no-console
    console.log('NotificationDeadLetter indexes', indexes);
    const orgScoped = indexes.find(([fields]) => fields.orgId === 1 && fields.notificationId === 1);
    expect(orgScoped).toBeDefined();

    const ttlIndex = indexes.find(
      ([fields, opts]) => fields.createdAt === 1 && typeof opts?.expireAfterSeconds === 'number'
    );
    expect(ttlIndex?.[1]?.expireAfterSeconds).toBe(Number(DLQ_TTL_DAYS) * 24 * 60 * 60);
  });

  it('uses ObjectId for orgId and recipient.userId', () => {
    expect(NotificationDeadLetterModel.schema.path('orgId')?.instance).toBe('ObjectId');
    expect(NotificationDeadLetterModel.schema.path('orgId')?.options.required).toBe(true);

    const recipientUserId = NotificationDeadLetterModel.schema.path('recipient.userId');
    expect(recipientUserId?.instance).toBe('ObjectId');
  });
});

]]>
</file>

<file path="tests/unit/models/Property.test.ts">
<![CDATA[
/**
 * Property model unit tests - PRODUCTION READY
 *
 * ‚úÖ Uses REAL MongoDB Memory Server
 * ‚úÖ Tests with real database operations
 * ‚úÖ No mocking
 *
 * Tests:
 * - Schema validation (required fields, enums)
 * - Location and address information
 * - Property details and financial data
 * - Multi-tenant isolation
 * - Index verification
 * - Plugin integration (tenant isolation, audit)
 */

import { describe, it, expect, vi, beforeEach } from "vitest";
import mongoose from "mongoose";
import {
  setTenantContext,
  clearTenantContext,
} from "@/server/plugins/tenantIsolation";

let Property: mongoose.Model<any>;

beforeEach(async () => {
  clearTenantContext();

  // Verify mongoose is connected
  if (mongoose.connection.readyState !== 1) {
    throw new Error("Mongoose not connected - tests require active connection");
  }

  // Clear module cache to force fresh import
  vi.resetModules();

  // Import model (will reuse if already registered)
  const propertyModule = await import("@/server/models/Property");
  Property = propertyModule.Property as mongoose.Model<any>;

  // Set tenant context
  setTenantContext({ orgId: "org-test-prop-123" });

  // Verify model initialization
  if (!Property || !Property.schema) {
    throw new Error("Property model not properly initialized");
  }

  // Verify tenantIsolationPlugin applied
  if (!Property.schema.paths.orgId) {
    throw new Error(
      "Property schema missing orgId - tenantIsolationPlugin did not run",
    );
  }
});

function buildValidProperty(
  overrides: Record<string, any> = {},
): Record<string, any> {
  const orgId = new mongoose.Types.ObjectId();
  const createdById = new mongoose.Types.ObjectId();

  return {
    orgId,
    code: `PROP-${Math.random().toString(36).slice(2, 8).toUpperCase()}`,
    name: "Test Property",
    type: "RESIDENTIAL",
    address: {
      street: "123 Main Street",
      city: "Riyadh",
      region: "Central",
      country: "SA",
      coordinates: {
        lat: 24.7136,
        lng: 46.6753,
      },
    },
    createdBy: createdById,
    ...overrides,
  };
}

describe("Property model - Schema Validation", () => {
  it("should create property with valid minimal data", () => {
    const data = buildValidProperty();
    const doc = new Property(data);
    const err = doc.validateSync();

    expect(err).toBeUndefined();
    expect(doc.code).toBeDefined();
    expect(doc.name).toBeDefined();
    expect(doc.type).toBe("RESIDENTIAL");
  });

  it("should enforce required fields", () => {
    const requiredFields = [
      "orgId",
      "code",
      "name",
      "type",
      "address.coordinates.lat",
      "address.coordinates.lng",
    ] as const;

    for (const field of ["orgId", "code", "name", "type"]) {
      const data = buildValidProperty();
      delete data[field];
      const doc = new Property(data);
      const err = doc.validateSync();

      expect(
        err,
        `Expected validation error for missing field: ${field}`,
      ).toBeDefined();
    }
  });

  it("should validate type enum", () => {
    const validTypes = [
      "RESIDENTIAL",
      "COMMERCIAL",
      "INDUSTRIAL",
      "MIXED_USE",
      "LAND",
    ];

    for (const type of validTypes) {
      const doc = new Property(buildValidProperty({ type }));
      expect(doc.validateSync()).toBeUndefined();
    }

    const badDoc = new Property(
      buildValidProperty({ type: "INVALID_TYPE" as any }),
    );
    const err = badDoc.validateSync();
    expect(err).toBeDefined();
    expect(err?.errors?.type).toBeDefined();
  });

  it("should default address.country to SA", () => {
    const data = buildValidProperty({
      address: {
        street: "123 Main St",
        city: "Riyadh",
        coordinates: { lat: 24.7136, lng: 46.6753 },
      },
    });
    const doc = new Property(data);
    expect(doc.address.country).toBe("SA");
  });
});

describe("Property model - Database Operations", () => {
  it("should save property to real MongoDB", async () => {
    const data = buildValidProperty();
    const doc = new Property(data);

    const saved = await doc.save();

    expect(saved._id).toBeDefined();
    expect(saved.code).toBe(data.code);
    expect(saved.createdAt).toBeDefined();
    expect(saved.updatedAt).toBeDefined();
  });

  it("should find property by code", async () => {
    const propCode = "PROP-FIND-123";
    const data = buildValidProperty({ code: propCode });
    await Property.create(data);

    const found = await Property.findOne({ code: propCode });

    expect(found).toBeDefined();
    expect(found?.code).toBe(propCode);
    expect(found?.name).toBe(data.name);
  });

  it("should update property details", async () => {
    const data = buildValidProperty({ name: "Original Name" });
    const doc = await Property.create(data);

    doc.name = "Updated Name";
    await doc.save();

    const updated = await Property.findById(doc._id);
    expect(updated?.name).toBe("Updated Name");
  });

  it("should delete property from database", async () => {
    const data = buildValidProperty();
    const doc = await Property.create(data);

    await Property.deleteOne({ _id: doc._id });

    const found = await Property.findById(doc._id);
    expect(found).toBeNull();
  });
});

describe("Property model - Multi-tenant Isolation", () => {
  it("should enforce unique code per organization", async () => {
    const propCode = "PROP-UNIQUE-001";
    const orgId = new mongoose.Types.ObjectId();

    // Create first property
    await Property.create(buildValidProperty({ code: propCode, orgId }));

    // Try to create duplicate in same org - should fail
    await expect(
      Property.create(buildValidProperty({ code: propCode, orgId })),
    ).rejects.toThrow(/duplicate key|E11000/);
  });

  it("should allow same code in different organizations", async () => {
    const propCode = "PROP-SHARED-001";
    const org1Id = new mongoose.Types.ObjectId();
    const org2Id = new mongoose.Types.ObjectId();

    // Create property in org1
    setTenantContext({ orgId: org1Id });
    const prop1 = await Property.create(
      buildValidProperty({ code: propCode, orgId: org1Id }),
    );

    // Create property with same code in org2 - should succeed
    setTenantContext({ orgId: org2Id });
    const prop2 = await Property.create(
      buildValidProperty({ code: propCode, orgId: org2Id }),
    );

    expect(prop1.code).toBe(propCode);
    expect(prop2.code).toBe(propCode);
    expect(prop1.orgId.toString()).toBe(org1Id.toString());
    expect(prop2.orgId.toString()).toBe(org2Id.toString());
  });
});

describe("Property model - Location Information", () => {
  it("should require coordinates (lat, lng)", () => {
    const data = buildValidProperty();
    delete data.address.coordinates.lat;
    const doc1 = new Property(data);
    const err1 = doc1.validateSync();
    expect(err1).toBeDefined();
    expect(err1?.errors?.["address.coordinates.lat"]).toBeDefined();

    const data2 = buildValidProperty();
    delete data2.address.coordinates.lng;
    const doc2 = new Property(data2);
    const err2 = doc2.validateSync();
    expect(err2).toBeDefined();
    expect(err2?.errors?.["address.coordinates.lng"]).toBeDefined();
  });

  it("should store full address information", () => {
    const data = buildValidProperty({
      address: {
        street: "456 King Fahd Road",
        city: "Riyadh",
        region: "Central Region",
        postalCode: "11564",
        country: "SA",
        coordinates: {
          lat: 24.7136,
          lng: 46.6753,
        },
        district: "Olaya",
        nationalAddress: "RRJJ2345",
      },
    });
    const doc = new Property(data);

    expect(doc.address.street).toBe("456 King Fahd Road");
    expect(doc.address.city).toBe("Riyadh");
    expect(doc.address.region).toBe("Central Region");
    expect(doc.address.postalCode).toBe("11564");
    expect(doc.address.district).toBe("Olaya");
    expect(doc.address.nationalAddress).toBe("RRJJ2345");
    expect(doc.address.coordinates.lat).toBe(24.7136);
    expect(doc.address.coordinates.lng).toBe(46.6753);
  });
});

describe("Property model - Property Details", () => {
  it("should store property details", () => {
    const data = buildValidProperty({
      details: {
        totalArea: 200,
        builtArea: 180,
        bedrooms: 3,
        bathrooms: 2,
        floors: 2,
        parkingSpaces: 2,
        yearBuilt: 2020,
        occupancyRate: 85,
      },
    });
    const doc = new Property(data);

    expect(doc.details.totalArea).toBe(200);
    expect(doc.details.bedrooms).toBe(3);
    expect(doc.details.bathrooms).toBe(2);
    expect(doc.details.floors).toBe(2);
    expect(doc.details.occupancyRate).toBe(85);
  });

  it("should validate occupancyRate boundaries (0-100)", () => {
    let doc = new Property(
      buildValidProperty({
        details: { occupancyRate: -1 },
      }),
    );
    expect(doc.validateSync()?.errors?.["details.occupancyRate"]).toBeDefined();

    doc = new Property(
      buildValidProperty({
        details: { occupancyRate: 101 },
      }),
    );
    expect(doc.validateSync()?.errors?.["details.occupancyRate"]).toBeDefined();

    doc = new Property(
      buildValidProperty({
        details: { occupancyRate: 0 },
      }),
    );
    expect(doc.validateSync()).toBeUndefined();

    doc = new Property(
      buildValidProperty({
        details: { occupancyRate: 100 },
      }),
    );
    expect(doc.validateSync()).toBeUndefined();
  });
});

describe("Property model - Financial Information", () => {
  it("should store financial data", () => {
    const data = buildValidProperty({
      financial: {
        purchasePrice: 1500000,
        currentValue: 1800000,
        monthlyRent: 5000,
        annualYield: 4.2,
        mortgage: {
          amount: 1000000,
          monthlyPayment: 4500,
          interestRate: 3.5,
          remaining: 800000,
        },
      },
    });
    const doc = new Property(data);

    expect(doc.financial.purchasePrice).toBe(1500000);
    expect(doc.financial.currentValue).toBe(1800000);
    expect(doc.financial.monthlyRent).toBe(5000);
    expect(doc.financial.annualYield).toBe(4.2);
    expect(doc.financial.mortgage.amount).toBe(1000000);
    expect(doc.financial.mortgage.remaining).toBe(800000);
  });
});

describe("Property model - Ownership", () => {
  it("should validate ownership.type enum", () => {
    const validTypes = ["OWNED", "LEASED", "MANAGED"];

    for (const type of validTypes) {
      const doc = new Property(
        buildValidProperty({
          ownership: { type },
        }),
      );
      expect(doc.validateSync()).toBeUndefined();
    }
  });

  it("should store ownership information", () => {
    const data = buildValidProperty({
      ownership: {
        type: "OWNED",
        owner: {
          name: "Property Owner LLC",
          contact: "+966501234567",
          id: "1234567890",
        },
      },
    });
    const doc = new Property(data);

    expect(doc.ownership.type).toBe("OWNED");
    expect(doc.ownership.owner.name).toBe("Property Owner LLC");
    expect(doc.ownership.owner.contact).toBe("+966501234567");
    expect(doc.ownership.owner.id).toBe("1234567890");
  });

  it("should store lease information", () => {
    const leaseStart = new Date("2025-01-01");
    const leaseEnd = new Date("2025-12-31");

    const data = buildValidProperty({
      ownership: {
        type: "LEASED",
        lease: {
          startDate: leaseStart,
          endDate: leaseEnd,
          monthlyRent: 8000,
          landlord: "Building Owner",
        },
      },
    });
    const doc = new Property(data);

    expect(doc.ownership.lease.startDate).toEqual(leaseStart);
    expect(doc.ownership.lease.endDate).toEqual(leaseEnd);
    expect(doc.ownership.lease.monthlyRent).toBe(8000);
    expect(doc.ownership.lease.landlord).toBe("Building Owner");
  });
});

describe("Property model - Plugins", () => {
  it("should have orgId field from tenantIsolationPlugin", () => {
    expect(Property.schema.paths.orgId).toBeDefined();
  });

  it("should have audit fields from auditPlugin", () => {
    expect(Property.schema.paths.createdBy).toBeDefined();
    expect(Property.schema.paths.updatedBy).toBeDefined();
    expect(Property.schema.paths.version).toBeDefined();
  });

  it("should have timestamps enabled", () => {
    expect(Property.schema.options.timestamps).toBe(true);
    expect(Property.schema.paths.createdAt).toBeDefined();
    expect(Property.schema.paths.updatedAt).toBeDefined();
  });
});

]]>
</file>

<file path="tests/unit/models/User.test.ts">
<![CDATA[
/**
 * User model unit tests - PRODUCTION READY
 * 
 * ‚úÖ Uses REAL MongoDB Memory Server
 * ‚úÖ Tests with real database operations
 * ‚úÖ No mocking
 * 
 * Tests:
 * - Schema validation (email, password, role)
 * - Required fields enforcement
 * - Email uniqueness per organization (multi-tenant)
 * - Role enum validation
 * - Default values (isActive, permissions)
 * - Index verification (orgId + email unique)
 * - Plugin integration (tenant isolation, audit)
 */

import { describe, it, expect, vi, beforeEach } from 'vitest';
import mongoose from 'mongoose';
import { setTenantContext, clearTenantContext } from '@/server/plugins/tenantIsolation';
import { Role } from '@/domain/fm/fm.behavior';

// Model imported AFTER mongoose connection
let User: mongoose.Model<any>;

beforeEach(async () => {
  clearTenantContext();
  
  // Verify mongoose is connected
  if (mongoose.connection.readyState !== 1) {
    throw new Error('Mongoose not connected - tests require active connection');
  }
  
  // Clear module cache to force fresh import
  vi.resetModules();
  
  // Import model (will reuse if already registered)
  const userModule = await import('@/modules/users/schema');
  User = userModule.User as mongoose.Model<any>;
  
  // Set tenant context
  setTenantContext({ orgId: 'org-test-123' });
  
  // Verify model initialized
  if (!User || !User.schema) {
    throw new Error('User model not properly initialized');
  }
  
  // Verify tenantIsolationPlugin applied
  if (!User.schema.paths.orgId) {
    throw new Error('User schema missing orgId - tenantIsolationPlugin did not run');
  }
});

/**
 * Build valid user data with all required fields
 */
function buildValidUser(overrides: Record<string, any> = {}): Record<string, any> {
  const orgId = new mongoose.Types.ObjectId();
  const createdById = new mongoose.Types.ObjectId();
  
  return {
    orgId,
    email: `test-${Math.random().toString(36).slice(2)}@example.com`,
    passwordHash: '$2a$10$abcdefghijklmnopqrstuv', // bcrypt hash format
    name: 'Test User',
    role: Role.TECHNICIAN, // Use actual Role enum value
    permissions: [],
    isActive: true,
    createdBy: createdById,
    ...overrides,
  };
}

describe('User model - Schema Validation', () => {
  it('should create user with valid minimal data', () => {
    const data = buildValidUser();
    const doc = new User(data);
    const err = doc.validateSync();
    
    expect(err).toBeUndefined();
    expect(doc.email).toBeDefined();
    expect(doc.name).toBeDefined();
    expect(doc.role).toBe(Role.TECHNICIAN);
    expect(doc.isActive).toBe(true);
  });

  it('should apply default values for isActive and permissions', () => {
    const data = buildValidUser({ isActive: undefined, permissions: undefined });
    const doc = new User(data);
    const err = doc.validateSync();
    
    expect(err).toBeUndefined();
    expect(doc.isActive).toBe(true);
    expect(doc.permissions).toEqual([]);
  });

  it('should enforce required fields: email, passwordHash, name, role', () => {
    const requiredFields = ['email', 'passwordHash', 'name', 'role'] as const;
    
    for (const field of requiredFields) {
      const data = buildValidUser();
      delete data[field];
      const doc = new User(data);
      const err = doc.validateSync();
      
      expect(err).toBeDefined();
      expect(err?.errors?.[field]).toBeDefined();
    }
  });

  it('should lowercase and trim email addresses', () => {
    const data = buildValidUser({ email: '  TEST@EXAMPLE.COM  ' });
    const doc = new User(data);
    
    expect(doc.email).toBe('test@example.com');
  });

  it('should trim name field', () => {
    const data = buildValidUser({ name: '  John Doe  ' });
    const doc = new User(data);
    
    expect(doc.name).toBe('John Doe');
  });
});

describe('User model - Role Validation', () => {
  it('should accept valid roles from Role enum', () => {
    const validRoles = [
      Role.SUPER_ADMIN,
      Role.CORPORATE_ADMIN,
      Role.MANAGEMENT,
      Role.TECHNICIAN,
      Role.TENANT,
      Role.VENDOR
    ];

    for (const role of validRoles) {
      const data = buildValidUser({ role });
      const doc = new User(data);
      const err = doc.validateSync();
      
      expect(err).toBeUndefined();
      expect(doc.role).toBe(role);
    }
  });

  it('should reject invalid roles', () => {
    const data = buildValidUser({ role: 'INVALID_ROLE' });
    const doc = new User(data);
    const err = doc.validateSync();
    
    expect(err).toBeDefined();
    expect(err?.errors?.role).toBeDefined();
  });
});

describe('User model - Database Operations', () => {
  it('should save user to real MongoDB', async () => {
    const data = buildValidUser();
    const doc = new User(data);
    
    const saved = await doc.save();
    
    expect(saved._id).toBeDefined();
    expect(saved.email).toBe(data.email);
    expect(saved.createdAt).toBeDefined();
    expect(saved.updatedAt).toBeDefined();
  });

  it('should find user by email in tenant context', async () => {
    const data = buildValidUser({ email: 'findme@example.com' });
    await User.create(data);
    
    const found = await User.findOne({ email: 'findme@example.com' });
    
    expect(found).toBeDefined();
    expect(found?.email).toBe('findme@example.com');
    // orgId is ObjectId, not string
    expect(found?.orgId.toString()).toBe(data.orgId.toString());
  });

  it('should enforce unique email per organization (multi-tenant)', async () => {
    const email = 'duplicate@example.com';
    const orgId = new mongoose.Types.ObjectId();
    
    // Create first user
    await User.create(buildValidUser({ email, orgId }));
    
    // Try to create duplicate in same org - should fail with duplicate key error
    await expect(
      User.create(buildValidUser({ email, orgId }))
    ).rejects.toThrow(/duplicate key|E11000/);
  });

  it('should allow same email in different organizations', async () => {
    const email = 'sameemail@example.com';
    const org1Id = new mongoose.Types.ObjectId();
    const org2Id = new mongoose.Types.ObjectId();
    
    // Create user in org1
    setTenantContext({ orgId: org1Id });
    const user1 = await User.create(buildValidUser({ email, orgId: org1Id }));
    
    // Create user with same email in org2 - should succeed
    setTenantContext({ orgId: org2Id });
    const user2 = await User.create(buildValidUser({ email, orgId: org2Id }));
    
    expect(user1.email).toBe(email);
    expect(user2.email).toBe(email);
    expect(user1.orgId.toString()).toBe(org1Id.toString());
    expect(user2.orgId.toString()).toBe(org2Id.toString());
  });

  it('should update user and track updatedAt timestamp', async () => {
    const data = buildValidUser();
    const doc = await User.create(data);
    
    const originalUpdatedAt = doc.updatedAt;
    
    // Wait a bit to ensure timestamp difference
    await new Promise(resolve => setTimeout(resolve, 10));
    
    doc.name = 'Updated Name';
    await doc.save();
    
    expect(doc.name).toBe('Updated Name');
    expect(doc.updatedAt.getTime()).toBeGreaterThan(originalUpdatedAt.getTime());
  });

  it('should delete user from database', async () => {
    const data = buildValidUser({ email: 'deleteme@example.com' });
    const doc = await User.create(data);
    
    await User.deleteOne({ _id: doc._id });
    
    const found = await User.findById(doc._id);
    expect(found).toBeNull();
  });
});

describe('User model - Indexes', () => {
  it('should have compound unique index on orgId + email', () => {
    const indexes = User.schema.indexes();
    
    const hasUniqueEmailIndex = indexes.some(([fields, options]) => {
      return fields.orgId === 1 && fields.email === 1 && options?.unique === true;
    });
    
    expect(hasUniqueEmailIndex).toBe(true);
  });

  it('should have compound unique sparse index on orgId + employeeId', () => {
    const indexes = User.schema.indexes();
    
    const hasEmployeeIdIndex = indexes.some(([fields, options]) => {
      return fields.orgId === 1 && 
             fields.employeeId === 1 && 
             options?.unique === true && 
             options?.sparse === true;
    });
    
    expect(hasEmployeeIdIndex).toBe(true);
  });

  it('should have index on orgId + role + isActive', () => {
    const indexes = User.schema.indexes();
    
    const hasRoleIndex = indexes.some(([fields]) => {
      return fields.orgId === 1 && fields.role === 1 && fields.isActive === 1;
    });
    
    expect(hasRoleIndex).toBe(true);
  });
});

describe('User model - Plugins', () => {
  it('should have orgId field from tenantIsolationPlugin', () => {
    expect(User.schema.paths.orgId).toBeDefined();
  });

  it('should have audit fields from auditPlugin', () => {
    expect(User.schema.paths.createdBy).toBeDefined();
    expect(User.schema.paths.updatedBy).toBeDefined();
    expect(User.schema.paths.version).toBeDefined();
  });

  it('should have timestamps enabled', () => {
    expect(User.schema.options.timestamps).toBe(true);
    expect(User.schema.paths.createdAt).toBeDefined();
    expect(User.schema.paths.updatedAt).toBeDefined();
  });

  it('should exclude passwordHash from select by default', () => {
    const passwordField = User.schema.paths.passwordHash;
    expect(passwordField.options.select).toBe(false);
  });
});

describe('User model - Optional Fields', () => {
  it('should allow optional employeeId', async () => {
    const data = buildValidUser({ employeeId: 'EMP-12345' });
    const doc = await User.create(data);
    
    expect(doc.employeeId).toBe('EMP-12345');
  });

  it('should allow user without employeeId', async () => {
    const data = buildValidUser({ role: Role.TECHNICIAN }); // Explicitly set role
    delete data.employeeId;
    const doc = await User.create(data);
    
    expect(doc.employeeId).toBeUndefined();
    expect(doc.role).toBe(Role.TECHNICIAN);
  });

  it('should store optional email verification timestamp', async () => {
    const verifiedAt = new Date();
    const data = buildValidUser({ emailVerifiedAt: verifiedAt });
    const doc = await User.create(data);
    
    expect(doc.emailVerifiedAt).toBeDefined();
    expect(doc.emailVerifiedAt.getTime()).toBe(verifiedAt.getTime());
  });

  it('should store optional last login timestamp', async () => {
    const lastLogin = new Date();
    const data = buildValidUser({ lastLoginAt: lastLogin });
    const doc = await User.create(data);
    
    expect(doc.lastLoginAt).toBeDefined();
    expect(doc.lastLoginAt.getTime()).toBe(lastLogin.getTime());
  });

  it('should store permissions array', async () => {
    const permissions = ['read:reports', 'write:work-orders', 'delete:assets'];
    const data = buildValidUser({ permissions });
    const doc = await User.create(data);
    
    expect(doc.permissions).toEqual(permissions);
  });
});

]]>
</file>

</batch_content>
